{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective 1: Build a SURROGATE MODEL using RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model import models\n",
    "from model import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device for training- (cpu, cuda or mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the type of encoder model, predictor model you want and loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Encoders available: \n",
    "   - 'PCA'\n",
    "   - 'Linear'\n",
    "   - 'CVAE'\n",
    "   - 'CAE1'\n",
    "   - 'CAE2' or 'best'\n",
    "\n",
    "\n",
    " - Decoders available:\n",
    "   - 'LSTM0'\n",
    "   - 'LSTM1'\n",
    "\n",
    "\n",
    " - Loss functions available:\n",
    "   - 'MSE'\n",
    "   - 'L1Loss'\n",
    "   - 'BCE'\n",
    "   - 'MSSSIM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = 'PCA'\n",
    "predictor_model = 'best'\n",
    "loss_type = 'BCE'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data/Ferguson_fire_train.npy'\n",
    "test_data_path = 'data/Ferguson_fire_test.npy'\n",
    "obs_data_path = 'data/Ferguson_fire_obs.npy'\n",
    "background_data_path = 'data/Ferguson_fire_background.npy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = models.load_encoder(encoder_model, device=device)\n",
    "loss_function = models.load_loss_function(loss_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show model details\n",
    "if isinstance(model_encoder, PCA):\n",
    "    print(np.cumsum(model_encoder.explained_variance_ratio_)[-1]*100, \"%\")\n",
    "else:\n",
    "    model_encoder.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataloader.load_data(dataset_path=train_data_path, model=model_encoder, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for torch.nn models\n",
    "\n",
    "# losses = models.train_model(epochs=25, model=model_encoder, data_loader=train_data, learning_rate=0.001, loss_function=loss_function, device=device)\n",
    "\n",
    "if isinstance(model_encoder, PCA):\n",
    "    print(np.cumsum(model_encoder.explained_variance_ratio_)[-1]*100, \"%\")\n",
    "else:\n",
    "    model_encoder.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoencoder results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_array = np.load(test_data_path)\n",
    "test_data = dataloader.load_data(dataset_path=test_data_path, model=model_encoder, batch_size=10, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model_encoder, PCA):\n",
    "    test_batch = test_data[:5].reshape(-1, 256*256)\n",
    "    outputs = model_encoder.transform(test_batch)\n",
    "    outputs = model_encoder.inverse_transform(outputs)\n",
    "    outputs = outputs.reshape(-1, 256, 256)\n",
    "    test_batch = test_batch.reshape(-1, 256, 256)\n",
    "    print(outputs.shape)\n",
    "else:\n",
    "    test_loader = iter(test_data)\n",
    "    test_batch = next(test_loader)\n",
    "    test_batch = test_batch[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_encoder(test_batch.to(device))\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        test_batch = test_batch.cpu().numpy()\n",
    "\n",
    "# Plotting the results\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 10))\n",
    "for i in range(5):\n",
    "    ax[0, i].imshow(test_batch[i], cmap='magma')\n",
    "    ax[1, i].imshow(outputs[i], cmap='magma')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress training data into latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model_encoder, PCA):\n",
    "    train_latent = model_encoder.transform(train_data.reshape(train_data.shape[0], -1))\n",
    "else:\n",
    "    train_latent = np.zeros((1, 64))\n",
    "    with torch.no_grad():\n",
    "        for x, _ in train_data:\n",
    "            data = np.array(model_encoder.encode(x.to(device)).cpu().numpy())\n",
    "            train_latent = np.concatenate((train_latent, data), axis=0)\n",
    "    train_latent = train_latent[1:, :]\n",
    "    print(train_latent.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load predictor(LSTM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = outputs_size = train_latent.shape[-1]\n",
    "\n",
    "model_predictor = models.load_predictor('best', model_encoder=model_encoder, input_size=input_size, output_size=outputs_size, device=device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train predictor on latent space data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function for predictor\n",
    "\n",
    "loss_function = models.load_loss_function('MSE')\n",
    "\n",
    "#Change hyperparameters based on compression method\n",
    "if isinstance(model_encoder, PCA):\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 200\n",
    "else:\n",
    "    learning_rate = 0.0001\n",
    "    num_epochs = 600\n",
    "\n",
    "# Load the latent space data into a dataloader\n",
    "train_latent_loader = dataloader.load_data(dataset_path=train_latent, model=model_predictor, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = models.train_model(epochs=num_epochs, model=model_predictor, data_loader=train_latent_loader, learning_rate=learning_rate, loss_function=loss_function, device=device)\n",
    "model_predictor.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the training loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test prediction model on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_performance(model_predictor, model_encoder, test_data, timesteps):\n",
    "    \"\"\" Test the performance of the model on the test data \n",
    "    \n",
    "    Args:   \n",
    "        model_predictor: The trained predictor model\n",
    "        model_encoder: The trained encoder model\n",
    "        test_data: The test data\n",
    "        timesteps: The number of timesteps to use for the prediction\n",
    "        \n",
    "        Returns:\n",
    "            mse_latent: The mean squared error of the latent space\n",
    "            mse_physical: The mean squared error of the physical space\n",
    "            \n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(model_encoder, PCA):\n",
    "        test_compressed = model_encoder.transform(test_data.reshape(test_data.shape[0], -1))\n",
    "    else:\n",
    "        #Create dataloader for memory safety\n",
    "        test_data_loader = dataloader.load_data(dataset_path=test_data, model=model_encoder, timesteps=timesteps, batch_size=100, shuffle=False);\n",
    "        test_compressed = np.zeros((1, 64))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, _ in test_data_loader:\n",
    "                data = np.array(model_encoder.encode(x.view(-1, 1, 256, 256).to(device)).cpu().numpy())\n",
    "                test_compressed = np.concatenate((test_compressed, data), axis=0)\n",
    "\n",
    "        test_compressed = test_compressed[1:, :]\n",
    "\n",
    "    # Create test set and targets as in training set\n",
    "    test_compresed_dataloader = dataloader.load_data(dataset_path=test_compressed, model=model_predictor, timesteps=timesteps, batch_size=100, shuffle=False);\n",
    "\n",
    "    mse_latent = 0\n",
    "    mse_physical = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_compresed_dataloader:\n",
    "            output = model_predictor(x.to(device))\n",
    "            mse_latent += loss_function(output, y.to(device)).item()\n",
    "\n",
    "            if isinstance(model_encoder, PCA):\n",
    "                outputs_inverse = model_encoder.inverse_transform(output.cpu().numpy())\n",
    "                targets_inverse = model_encoder.inverse_transform(y.numpy())\n",
    "                mse_physical += loss_function(torch.Tensor(outputs_inverse), torch.Tensor(targets_inverse)).item()\n",
    "            else:\n",
    "                outputs_inverse = model_encoder.decode(output.view(-1, 1, 64))\n",
    "                targets_inverse = model_encoder.decode(y.view(-1, 1, 64).to(device))\n",
    "                mse_physical += loss_function(torch.Tensor(outputs_inverse), torch.Tensor(targets_inverse)).item()\n",
    "\n",
    "\n",
    "    print(f\"Test loss on latent space: {mse_latent}\")\n",
    "    print(f\"Test loss on physical space: {mse_physical}\")\n",
    "\n",
    "    return mse_latent, mse_physical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why are we calculating MSE between compressed and then decompressed target and output from LSTM?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(test_data_path)\n",
    "test_data_performance(model_predictor, model_encoder, test_data, timesteps=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the background and observation data\n",
    "\n",
    "background_data = np.load(background_data_path)\n",
    "obs_data = np.load(obs_data_path)\n",
    "background_data.shape, obs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_background(model_encoder, model_predictor, background_data):\n",
    "    \"\"\" Predict on the background data\n",
    "\n",
    "    Args:\n",
    "        model_encoder: The trained encoder model\n",
    "        model_predictor: The trained predictor model\n",
    "        background_data: The background data\n",
    "    \n",
    "    Returns:\n",
    "        outputs_inverse: The outputs of the model on the background data\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(model_encoder, PCA):\n",
    "        background_compressed = model_encoder.transform(background_data.reshape(background_data.shape[0], -1))\n",
    "    else:\n",
    "        background_compressed = model_encoder.encode(torch.from_numpy(np.expand_dims(background_data, axis=1)).float().to(device)).cpu().detach().numpy()\n",
    "\n",
    "    # Move the inputs and targets to device\n",
    "    inputs = torch.Tensor(np.expand_dims(background_compressed, axis=1))\n",
    "\n",
    "    # Forward pass and get the outputs\n",
    "    outputs = model_predictor(inputs.to(device))\n",
    "\n",
    "    # Decompress the outputs\n",
    "    if isinstance(model_encoder, PCA):\n",
    "        outputs_inverse = model_encoder.inverse_transform(outputs.detach().cpu().numpy()).reshape(-1, 256, 256)\n",
    "    else:\n",
    "        outputs_inverse = model_encoder.decode(outputs).detach().cpu().numpy().reshape(-1, 256, 256)\n",
    "\n",
    "    # Print the loss\n",
    "    return outputs_inverse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform prediction on background data\n",
    "background_predict = predict_on_background(model_encoder=model_encoder, model_predictor=model_predictor, background_data=background_data)\n",
    "\n",
    "# Store the background prediction to perform data assmilations\n",
    "np.save('data/predictions_lstm.npy', background_predict[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_background_obs(backgound_data, background_predict, obs_data):\n",
    "    \"\"\" Plot the background, observation and prediction data\n",
    "\n",
    "    Args:\n",
    "        backgound_data: The background data\n",
    "        background_predict: The background prediction\n",
    "        obs_data: The observation data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set same colorbar range for all plots\n",
    "    vmin = 0\n",
    "    vmax = 1\n",
    "    # Create subplots and set colorbar\n",
    "    _, axes = plt.subplots(3, 6, figsize=(20, 10))\n",
    "\n",
    "    for i in range(backgound_data.shape[0]):\n",
    "        cax = axes[0, i].imshow(backgound_data[i], vmin=vmin, vmax=vmax)\n",
    "        axes[0, i].set_title(f\"Background {i+1}\")\n",
    "        axes[1, i+1].imshow(background_predict[i], vmin=vmin, vmax=vmax)\n",
    "        axes[1, i+1].set_title(f\"Prediction {i+1}\")\n",
    "        axes[2, i].imshow(obs_data[i], vmin=vmin, vmax=vmax)\n",
    "        axes[2, i].set_title(f\"Observation {i+1}\")\n",
    "    plt.colorbar(cax, ax=axes.ravel().tolist())\n",
    "    # Do not show axis \n",
    "    for ax in axes.ravel():\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    Plot the background, prediction and observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_background_obs(background_data, background_predict, obs_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE between the backgound and the their corresponding predictions\n",
    "loss = loss_function(torch.Tensor(background_predict[:4]), torch.Tensor(background_data[1:]))\n",
    "loss.item()\n",
    "\n",
    "# Write results to file\n",
    "with open('results_lstm.txt', 'a') as f:\n",
    "    if isinstance(model_encoder, PCA):\n",
    "        f.write(f\"Loss on prediction on background data for PCA: {loss.item()}\\n\")\n",
    "    else:\n",
    "        f.write(f\"Loss on prediction on background data for Autoencoder: {loss.item()}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did we learn:\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We started with ConvolutionLSTM, it gave good results comparatively. However, the training was very expensive due to limited hardware. Therefore we adopted Reduced Order Modelling. \n",
    "2. Using an autoencoder to compress images and then using an LSTM for prediction in latent space. This was quick to train. However, the error propagated at every step from one model to another.\n",
    "3. Ultimately, we used PCA since it gave best results and the data does have non-linearity but not too high. It is able to represent the data within managable PC's for LSTM's latent space.\n",
    "3. The advantage of this approach is it can scale with the data size(image resolution or number of images). Since, the LSTM predicts in latent space.\n",
    "4. We experimented with various loss functions for encoder, in our testing use of perception index loss(MSSSIM) gave good reconstruction of the data. But, it did notshow good results when trained for low epochs.\n",
    "5. We explored using different loss function, because the given dataset has most of the pixel values as 0, so however bad the model performed the MSE loss was less than 1. This also had an affect on reconstructed images. The images wildfire images did not look like the wildfire scenarios anymore. That's why we used MSSIM perception index so that it can at least replicate the real scenarios. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
